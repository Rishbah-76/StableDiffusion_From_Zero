{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as f\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Job of Encoder is to reduce the dimension of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class selfAttention(nn.Module):\n",
    "    def __init__(self,n_heads:int,d_embed:int, in_proj_bias=True ,out_proj_bias=True):\n",
    "        super().__init__()\n",
    "        self.in_proj=nn.Linear(d_embed,3*d_embed,bias=in_proj_bias)\n",
    "        self.out_proj=nn.Linear(d_embed,d_embed,bias=out_proj_bias)\n",
    "        self.heads=n_heads\n",
    "        self.d_head=d_embed//n_heads\n",
    "\n",
    "    def forward(self, x, casual_mask=False):\n",
    "        # x: (Batch_size,seq_length (len_of_embed),Dim)\n",
    "        input_shape=x.shape\n",
    "        batch_size,seq_len,d_embed=input_shape\n",
    "\n",
    "        # required for converting the input into desired input for K,q,v\n",
    "        intermin_shape=(batch_size,seq_len,self.heads,self.d_head)\n",
    "\n",
    "        # (Batch_size,seq_length (len_of_embed),Dim)--> (Batch_size,seq_length (len_of_embed),Dim*3 )--> 3 tensors of shape  (Batch_size,seq_length (len_of_embed),Dim)\n",
    "        k,q,v=self.in_proj(x).chunk(3,dim=-1) # to the last dim which is itself in this case is \"DIM\"\n",
    "\n",
    "        # splitting the number of k,q,v in n_heads\n",
    "\n",
    "\n",
    "# transpose(): Swaps two dimensions of a tensor, effectively changing the arrangement of the data.\n",
    "# view(): Reshapes the tensor without changing its data. The number of elements must remain the same.\n",
    "\n",
    "#Creating Q, K, V:\n",
    "# For each word, we create Q, K, and V (in practice, these are learned linear transformations of the embeddings).\n",
    "\n",
    "        q=q.view(intermin_shape).transpose(1,2)  #(Batch_size,seq_length,Dim )--> (Batch_size,seq_length, Heads, DIM/Heads )\n",
    "        k=k.view(intermin_shape).transpose(1,2)  #(Batch_size,seq_length,Dim )--> (Batch_size,seq_length, Heads, DIM/Heads )\n",
    "        v=v.view(intermin_shape).transpose(1,2) #(Batch_size,seq_length,Dim )--> (Batch_size,seq_length, Heads, DIM/Heads )\n",
    "\n",
    "\n",
    "        # doing the weights \n",
    "        weights= q@k.transpose(-1,-2)\n",
    "\n",
    "        if casual_mask: # so that we can disaacoatiate simliars tokens nex to each other, makes a -infity passed to softmax--> gives 0\n",
    "            # mask where the upper traingles are 1 above the principal Diagonal\n",
    "            mask=torch.ones_like(weights,dtype=torch.bool).triu(1)\n",
    "            weights.masked_fill(mask,-torch.inf)\n",
    "\n",
    "        weights/=math.sqrt(self.d_head)\n",
    "        weights=f.softmax(weights,dim=-1)\n",
    "\n",
    "        output=weights@v # (Batch_size,Heads,Seq_len,Seq_len ) @ (Batch_size,Heads,Seq_len,DIM/Heads ) --> (Batch_size,Heads,Seq_len,DIM/Heads )\n",
    "        \n",
    "        output.transpose(1,2) #m (Batch_size , Seq_len, Heads, DIM/Heads )\n",
    "\n",
    "        output=output.reshape(input_shape)\n",
    "\n",
    "        output=self.out_proj(output)\n",
    "\n",
    "        # (Batch_size,seq_length,Dim )\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the VAE_residual Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self VAE Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_AttentionBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.groupNorm= nn.GroupNorm(32, channels)\n",
    "        self.attention=selfAttention(1,channels)\n",
    "\n",
    "    def forward(self, x :torch.Tensor)-> torch.Tensor:\n",
    "        residue=x\n",
    "        n,c,h,w=x.shape()\n",
    "        \n",
    "        #(BAtch size, Feautures(respected embeds), height , widht) --> (BAtch size, Feautures(respected embeds), height * widht)\n",
    "        x=x.view(n,c,w*h)\n",
    "\n",
    "        # (BAtch size, Feautures(respected embeds), height , widht)--> (BAtch size, , height * widht, Feautures(respected embeds))\n",
    "        x=x.transpose(-1,-2)\n",
    "\n",
    "        x=self.attention(x)\n",
    "\n",
    "        x=x.transpose(-1,-2)\n",
    "        x=x.view((n,c,h,w))\n",
    "        x+=residue\n",
    "\n",
    "        residue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.groupNorm_1=nn.GroupNorm(32,in_channels) # this doesnt change the --> input , outputsize\n",
    "        self.conv_1= nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1)  # this also doesnt change the output as there padding introducted\n",
    "        self.groupNorm_2=nn.GroupNorm(32,out_channels)\n",
    "        self.conv_2=nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1)\n",
    "\n",
    "        if in_channels== out_channels:\n",
    "            self.residual_layer=nn.Identity()\n",
    "        else:\n",
    "            self.residual_layer=nn.Conv2d(in_channels,out_channels,kernel_size=1,padding=0) # to convert the layer just that input channel is equal to ouput channel\n",
    "\n",
    "    def forward(self,x:torch.Tensor)->torch.tensor:\n",
    "        # x: (Batch_size, In_channels, Height, Width)\n",
    "        residue = x\n",
    "        x=self.groupNorm_1(x)\n",
    "        x==f.silu(x)\n",
    "        x=self.conv_1(x)\n",
    "        x=self.groupNorm_2(x)\n",
    "        x=f.silu(x)\n",
    "        x=self.conv_2(x)\n",
    "        return x + self.residual_layer(residue)\n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from decoder import VAE_attentionBlock, VAE_residualBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the encoder Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "┌──────────────────────────────────────────────────────────────────┐\n",
    "│  Input:  x ∈ ℝ^(B, 3, H, W)                                     │\n",
    "└──────────────────────────────────────────────────────────────────┘\n",
    "                   │\n",
    "                   ▼\n",
    "          Conv2D(3 → 128, 3×3, stride=1, pad=1)\n",
    "                   │  (same H×W, 128 channels)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(128 → 128)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (same H×W, 128 channels)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(128 → 128)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (same H×W, 128 channels)\n",
    "                   ▼\n",
    "          Conv2D(128 → 128, 3×3, stride=2, pad=0)\n",
    "                   │  (H/2 × W/2, 128 channels; note: padded)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(128 → 256)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (H/2 × W/2, 256 channels)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(256 → 256)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (H/2 × W/2, 256 channels)\n",
    "                   ▼\n",
    "          Conv2D(256 → 256, 3×3, stride=2, pad=0)\n",
    "                   │  (H/4 × W/4, 256 channels; note: padded)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(256 → 512)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (H/4 × W/4, 512 channels)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(512 → 512)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (H/4 × W/4, 512 channels)\n",
    "                   ▼\n",
    "          Conv2D(512 → 512, 3×3, stride=2, pad=0)\n",
    "                   │  (H/8 × W/8, 512 channels; note: padded)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(512 → 512)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (H/8 × W/8, 512 channels)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(512 → 512)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (H/8 × W/8, 512 channels)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(512 → 512)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (H/8 × W/8, 512 channels)\n",
    "                   ▼\n",
    "               AttentionBlock(512 → 512)\n",
    "                   │  (H/8 × W/8, 512 channels)\n",
    "                   ▼\n",
    "          ┌────────────────────────────────────────────────────────┐\n",
    "          │  ResidualBlock(512 → 512)                             │\n",
    "          └────────────────────────────────────────────────────────┘\n",
    "                   │  (H/8 × W/8, 512 channels)\n",
    "                   ▼\n",
    "               GroupNorm(32, 512)\n",
    "                   │\n",
    "                   ▼\n",
    "                     SILU\n",
    "                   │\n",
    "                   ▼\n",
    "          Conv2D(512 → 8, 3×3, pad=1)\n",
    "                   │  (H/8 × W/8, 8 channels)\n",
    "                   ▼\n",
    "          Conv2D(8 → 8, 1×1, pad=0)\n",
    "                   │  (H/8 × W/8, 8 channels)\n",
    "                   ▼\n",
    "   ┌────────────────────────────────────────────────────────────────┐\n",
    "   │   Split along channel → mean (4 ch) and log_variance (4 ch)   │\n",
    "   └────────────────────────────────────────────────────────────────┘\n",
    "                   │\n",
    "                   ▼\n",
    "   Clamp log_variance to [-30, 20], then variance = exp(log_variance)\n",
    "                   │\n",
    "                   ▼\n",
    "          stdev = sqrt(variance)\n",
    "                   │\n",
    "                   ▼\n",
    "          z = mean + stdev * noise\n",
    "                   │\n",
    "                   ▼\n",
    "         Scale z by 0.18215 → (output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Encoder(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # batch size, channel, height , width\n",
    "        nn.Conv2d(3,128,3,1,1),\n",
    "        VAE_ResidualBlock(128,128), # does not change the size of the image : (Batch_size ,128,Height , width)--> remain same as --> (Batch_size ,128,Height , width)\n",
    "        VAE_ResidualBlock(128,128),\n",
    "        nn.Conv2d(128,128,kernel_size=3,stride=2,padding=0),\n",
    "        VAE_ResidualBlock(256,256),#--> only increases the number of Features with Height /2, Width/2 \n",
    "        VAE_ResidualBlock(256,256),#--> only increases the number of Features with Height /2, Width/2 \n",
    "        nn.Conv2d(256,256,kernel_size=3,stride=2,padding=0),            \n",
    "        VAE_ResidualBlock(256,512),#--> only increases the number of Features with Height /4, Width/4 \n",
    "        VAE_ResidualBlock(512,512),#--> only increases the number of Features with Height /4, Width/4\n",
    "        nn.Conv2d(512,512,kernel_size=3,stride=2, padding=0),\n",
    "        VAE_ResidualBlock(512,512),#--> only increases the number of Features with Height /8, Width/8 \n",
    "        VAE_ResidualBlock(512,512),#--> only increases the number of Features with Height /8, Width/8  \n",
    "        VAE_ResidualBlock(512,512),#--> only increases the number of Features with Height /8, Width/8  \n",
    "\n",
    "        ## ANNOTATION BLOCK ##--> seq to seq model\n",
    "        VAE_AttentionBlock(512,512), #Batch size, 512, Height /8, Width/8\n",
    "\n",
    "        VAE_ResidualBlock(512,512),#--> only increases the number of Features with Height /8, Width/8  \n",
    "        nn.GroupNorm(32,512),\n",
    "        nn.SILU(),\n",
    "        nn.Conv2d(512,8,kernel_size=3,padding=1), #Batch size, 8, Height /8, Width/8\n",
    "        nn.Conv2d(8,8,kernel_size=1,padding=0) #Batch size, 8, Height /8, Width/8\n",
    "\n",
    "    \n",
    "        \n",
    "    def forward(self,x: torch.Tensor,noise: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"params\n",
    "        x: (BatchSize, Channel, Height , Width)\n",
    "        noise: (BatchSize, out_channel,Height/8, width/8)\n",
    "        \"\"\"\n",
    "        for module in self:\n",
    "            if getattr(module, 'stride',None)==(2,2):\n",
    "                # padding_left, padding_right, padding_top, padding_bottom\n",
    "                x=f.pad(x,(0,1,0,1))\n",
    "            x=module(x)\n",
    "    \n",
    "        # (BatchSize, 8, Height/8 , Width/8) --> return two tensors of shape ((BatchSize, 4, Height/8 , Width/8)) i.e on dim=1\n",
    "        mean,log_variance=torch.chunk(x,2,dim=1)\n",
    "        log_variance=torch.clamp(log_variance,-30,20)# --> setting a range to log_variance if too small \n",
    "\n",
    "        variance=log_variance.exp()\n",
    "        stdev=variance.sqrt()\n",
    "\n",
    "        #now converting one distritbution to another with mean and variance\n",
    "        # if z=N(0,1)--> N(mean, variance)=x?\n",
    "        # ques: How we do it: Answer--> simply by x=mean+stdev*z\n",
    "        x=mean+stdev*noise\n",
    "        \n",
    "        # scaling the output by a constant\n",
    "        x*=0.18215\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE_Decoder(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            # (Batch_Size, 4, Height / 8, Width / 8) -> (Batch_Size, 4, Height / 8, Width / 8)\n",
    "            nn.Conv2d(4, 4, kernel_size=1, padding=0),\n",
    "\n",
    "            # (Batch_Size, 4, Height / 8, Width / 8) -> (Batch_Size, 512, Height / 8, Width / 8)\n",
    "            nn.Conv2d(4, 512, kernel_size=3, padding=1),\n",
    "            \n",
    "            # (Batch_Size, 512, Height / 8, Width / 8) -> (Batch_Size, 512, Height / 8, Width / 8)\n",
    "            VAE_ResidualBlock(512, 512), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 8, Width / 8) -> (Batch_Size, 512, Height / 8, Width / 8)\n",
    "            VAE_AttentionBlock(512), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 8, Width / 8) -> (Batch_Size, 512, Height / 8, Width / 8)\n",
    "            VAE_ResidualBlock(512, 512), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 8, Width / 8) -> (Batch_Size, 512, Height / 8, Width / 8)\n",
    "            VAE_ResidualBlock(512, 512), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 8, Width / 8) -> (Batch_Size, 512, Height / 8, Width / 8)\n",
    "            VAE_ResidualBlock(512, 512), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 8, Width / 8) -> (Batch_Size, 512, Height / 8, Width / 8)\n",
    "            VAE_ResidualBlock(512, 512), \n",
    "            \n",
    "            # Repeats the rows and columns of the data by scale_factor (like when you resize an image by doubling its size).\n",
    "            # (Batch_Size, 512, Height / 8, Width / 8) -> (Batch_Size, 512, Height / 4, Width / 4)\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            # (Batch_Size, 512, Height / 4, Width / 4) -> (Batch_Size, 512, Height / 4, Width / 4)\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 4, Width / 4) -> (Batch_Size, 512, Height / 4, Width / 4)\n",
    "            VAE_ResidualBlock(512, 512), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 4, Width / 4) -> (Batch_Size, 512, Height / 4, Width / 4)\n",
    "            VAE_ResidualBlock(512, 512), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 4, Width / 4) -> (Batch_Size, 512, Height / 4, Width / 4)\n",
    "            VAE_ResidualBlock(512, 512), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 4, Width / 4) -> (Batch_Size, 512, Height / 2, Width / 2)\n",
    "            nn.Upsample(scale_factor=2), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 2, Width / 2) -> (Batch_Size, 512, Height / 2, Width / 2)\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), \n",
    "            \n",
    "            # (Batch_Size, 512, Height / 2, Width / 2) -> (Batch_Size, 256, Height / 2, Width / 2)\n",
    "            VAE_ResidualBlock(512, 256), \n",
    "            \n",
    "            # (Batch_Size, 256, Height / 2, Width / 2) -> (Batch_Size, 256, Height / 2, Width / 2)\n",
    "            VAE_ResidualBlock(256, 256), \n",
    "            \n",
    "            # (Batch_Size, 256, Height / 2, Width / 2) -> (Batch_Size, 256, Height / 2, Width / 2)\n",
    "            VAE_ResidualBlock(256, 256), \n",
    "            \n",
    "            # (Batch_Size, 256, Height / 2, Width / 2) -> (Batch_Size, 256, Height, Width)\n",
    "            nn.Upsample(scale_factor=2), \n",
    "            \n",
    "            # (Batch_Size, 256, Height, Width) -> (Batch_Size, 256, Height, Width)\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), \n",
    "            \n",
    "            # (Batch_Size, 256, Height, Width) -> (Batch_Size, 128, Height, Width)\n",
    "            VAE_ResidualBlock(256, 128), \n",
    "            \n",
    "            # (Batch_Size, 128, Height, Width) -> (Batch_Size, 128, Height, Width)\n",
    "            VAE_ResidualBlock(128, 128), \n",
    "            \n",
    "            # (Batch_Size, 128, Height, Width) -> (Batch_Size, 128, Height, Width)\n",
    "            VAE_ResidualBlock(128, 128), \n",
    "            \n",
    "            # (Batch_Size, 128, Height, Width) -> (Batch_Size, 128, Height, Width)\n",
    "            nn.GroupNorm(32, 128), \n",
    "            \n",
    "            # (Batch_Size, 128, Height, Width) -> (Batch_Size, 128, Height, Width)\n",
    "            nn.SiLU(), \n",
    "            \n",
    "            # (Batch_Size, 128, Height, Width) -> (Batch_Size, 3, Height, Width)\n",
    "            nn.Conv2d(128, 3, kernel_size=3, padding=1), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch_Size, 4, Height / 8, Width / 8)\n",
    "        \n",
    "        # Remove the scaling added by the Encoder.\n",
    "        x /= 0.18215\n",
    "\n",
    "        for module in self:\n",
    "            x = module(x)\n",
    "\n",
    "        # (Batch_Size, 3, Height, Width)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
